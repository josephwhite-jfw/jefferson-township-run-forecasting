# ── 1. Load libraries ─────────────────────────────────────────────────────
library(tidyverse)
library(lubridate)
# ── 2. Read in the cleaned runs table ─────────────────────────────────────
runs <- read_csv("data/clean/runs_cleaned.csv",
col_types = cols(
incident_id = col_character(),
date        = col_datetime(format = ""),
.default    = col_character()
))
# ── 1. Load libraries ─────────────────────────────────────────────────────
library(tidyverse)
library(lubridate)
# ── 2. Read in the cleaned runs table ─────────────────────────────────────
runs <- read_csv("data/clean/fire_runs_cleaned.csv",
col_types = cols(
incident_id = col_character(),
date        = col_datetime(format = ""),
.default    = col_character()
))
# ── 3. Count runs per year ────────────────────────────────────────────────
runs_yearly <- runs %>%
mutate(year = year(date)) %>%
count(year, name = "run_count")
print(runs_yearly)
# ── 4. Plot runs per year with ggplot2 ────────────────────────────────────
ggplot(runs_yearly, aes(x = year, y = run_count)) +
geom_col(fill = "steelblue") +
labs(
title = "JTFD Runs per Year",
x     = "Year",
y     = "Number of Runs"
) +
theme_minimal()
library(tidyverse)
library(lubridate)
# reload if needed
runs <- read_csv("data/clean/runs_cleaned.csv",
col_types = cols(date = col_datetime()))
library(tidyverse)
library(lubridate)
# reload if needed
runs <- read_csv("data/clean/fire_runs_cleaned.csv",
col_types = cols(date = col_datetime()))
# 1. See which two runs have no year
runs %>%
filter(is.na(date)) %>%
select(incident_id, address) %>%
print(n = Inf)
# 2. Drop runs without a valid date
runs2 <- runs %>%
filter(!is.na(date))
# 3. Re‑tally per year
runs_yearly2 <- runs2 %>%
mutate(year = year(date)) %>%
count(year, name = "run_count")
print(runs_yearly2)
# 4. Re‑plot
ggplot(runs_yearly2, aes(x = year, y = run_count)) +
geom_col(fill = "steelblue") +
labs(
title = "JTFD Runs per Year (cleaned)",
x     = "Year",
y     = "Number of Runs"
) +
theme_minimal()
parcel_panel <- read_csv("data/clean/parcels_runs_by_street_year.csv")
# if you want township‑wide totals to compare:
street_totals <- parcel_panel %>%
group_by(year) %>%
summarize(total_sqft = sum(total_sqft, na.rm=TRUE),
total_parcels = sum(parcels),
runs = sum(run_count))
# join runs_yearly2 to street_totals and inspect:
yearly_panel <- street_totals %>%
left_join(runs_yearly2, by="year")
print(yearly_panel)
library(dplyr)
yearly_panel2 <- yearly_panel %>%
mutate(
run_count = coalesce(run_count, runs)
)
print(yearly_panel2)
panel <- read_csv("data/clean/parcels_jefferson_panel.csv")
panel %>% filter(source_year==2016) %>%
summarize(n_parcels=n(), sqft_nonzero=sum(area_a>0,na.rm=TRUE))
library(ggplot2)
ggplot(yearly_panel2, aes(x=year, y=run_count)) +
geom_col(fill="steelblue") +
labs(title="JTFD Runs per Year (2014–2024)",
x="Year", y="Run Count") +
theme_minimal()
library(MASS)
model <- glm.nb(
run_count ~ log(total_sqft) + factor(year),
data = yearly_panel2 %>% filter(total_sqft>0)
)
summary(model)
library(readr); library(dplyr); library(ggplot2)
library(MASS)       # for glm.nb
street_panel <- read_csv("data/clean/parcels_runs_by_street_year.csv",
col_types=cols(
street_norm    = col_character(),
year           = col_integer(),
parcels        = col_integer(),
total_sqft     = col_double(),
net_delta_sqft = col_double(),
run_count      = col_double()
))
# drop street–years with no sqft
df <- street_panel %>% filter(total_sqft > 0)
# add log_sqft
df <- df %>% mutate(log_sqft = log(total_sqft))
# 1) Poisson baseline
pois <- glm(run_count ~ log_sqft + factor(year),
data=df, family=poisson(link="log"))
summary(pois)
dispersion <- sum(residuals(pois, type="pearson")^2) / pois$df.residual
print(glue::glue("Dispersion ratio: {dispersion}"))
# 2) If over‑dispersed, NB:
nb  <- glm.nb(run_count ~ log_sqft + factor(year), data=df)
summary(nb)
